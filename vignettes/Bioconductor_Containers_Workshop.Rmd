---
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    toc_depth: 3
    fig_width: 5
bibliography: "`r file.path(system.file(package='Bioconductor_Containers_Workshop
', 'vignettes'), 'bibliography.bib')`"
vignette: >
  %\VignetteIndexEntry{Bioconductor_Containers_Workshop}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding[utf8]{inputenc}
---

# Bioconductor on Containers

## Beginners section - Topics

| Activity                     | Time |
|------------------------------|------|
| Why Containers & Why Docker  | 10m  |
| Bioconductor on Docker       | 10m  |
| Flavors of Bioconductor      | 10m  |
| Which flavor to use          | 10m  |
| How to mount volumes         | 10m  |
| Questions                    | Please interrupt me!! |

### Who is this for?

This workshop is for a **beginner**. You don't have to have any prior
experience with Docker or container technology. In this course
participants are expected to launch Docker images on their local
machines, mount volumes, and set ports as needed to use RStudio.

Since it's a beginners course, please note that we will be starting at
a basic level. The next section of the course, the advanced section
will give you deeper insight into how container technology can be used
on the cloud.

### Why Containers and Why Docker

A **Container** is a completely isolated environment. They can have
their own processes or services or network interfaces, volume mounts,
just like a virtual machine. They differ from VM's only in a single
aspect, they "share" the OS kernel. **Containers are running instances
of images.**

Docker is simply the most popular container technology being used
today. An **Image** is static (fixed) template and container is a
running version of the image. An image can be used to create a
container.

```{r image_one, echo=FALSE, out.width='75%'}
knitr::include_graphics(
    system.file("inst/vignettes", 
                "Docker_images_vs_containers.png", 
                package = "Bioconductor_Containers_Workshop"
                )
    )
```

It is important to note, every time you start a container from an image
it will take up the same amount of space as the image before you build
on it.  So, if you start a docker image of 1GB, the container takes up
1GB. The space being used on your machine is now 2GB. If you start 5
containers, they take up 1GB each for a container, so you are
consuming 5GB space.

**Main reason behind using containers**: As a user, you want to
delegate problems of software installation to the developer (in this
case - Bioconductor). Bioconductor gives you these static docker
images which solve this issue of software installation on your
infrastructure.

### Docker warmup

Get a list of docker images

```
docker images
```

Since there is nothing there, let's pull (get) an image specifically
`bioconductor/release_base2:latest`
(<organization>/<image_name>:<tag>).  This will take a minute or two.

```
docker pull bioconductor/release_base2:latest
```

Run the image to start a container (now we are getting somewhere!)

```
docker run -p 8787:8787 -e PASSWORD=bioc bioconductor/release_base2
```

Open a new terminal and you can check to see your container is running,

```
docker ps
```

Kill the container

```
docker kill <container_id>
```

Remove the image (you don't want to do this one right now)

```
docker rmi bioconductor/release_base2
```

Interactively running docker images ,

```
## For bash
docker run -it bioconductor/release_base2 bash

## For R directly
docker run -it bioconductor/release_base2 R
```

Interactively run Containers,

```
## Get the container ID
docker ps
```

```
docker exec -it <container ID>
```

### Bioconductor on Docker

In this section we will discuss what flavors are available to users,
and how to build on these images.

Bioconductor provides Docker images in a few ways:

#### [Bioconductor `bioc_docker` images](https://bioconductor.org/help/docker/)

These images are hosted on [Docker Hub](https://cloud.docker.com/u/bioconductor/repository/list). The
[bioconductor docker page](https://bioconductor.org/help/docker/) has
information and instructions on how to use them. The Dockerfile(s) for
each of these containers is located in
[github](https://github.com/Bioconductor/bioc_docker/tree/master/out). These
are provided directly by the Bioconductor team for each supported
version of Bioconductor and are categorized into,

1. base2: Contains R, RStudio, and a single Bioconductor package
   (`BiocManager`, providing the `install()` function for installing
   additional packages). Also contains many system dependencies for
   Bioconductor packages.

1. core2: It contains everything in base2, plus a selection of core
   Bioconductor packages.

    |Core packages|--|--|--|
    |--|--|--|--|--|
    |BiocManager | OrganismDbi| ExperimentHub | Biobase |BiocParallel |
    |biomaRt |Biostrings |BSgenome | ShortRead |IRanges |
    |GenomicRanges | GenomicAlignment |GenomicFeatures |SummarizedExperiment |VariantAnnotation |
    |DelayedArray | GSEABase | Gviz |graph | RBGL|
    |Rgraphviz|rmarkdown | httr | knitr| BiocStyle|
    |--|--|--|--|--|

1. protmetcore2: It contains everything in core2, plus a selection of
   core Bioconductor packages recommended for proteomic and
   metabolomics analysis. Reference section contains list of packages
   in protmetcore2

1. metabolomics2: It contains everything in protmetcore2, plus select
   packages from the Metabolomics biocView. Reference section contains
   list of packages in metabolomics2

1. cytometry2: Built on base2, so it contains everything in base2,
   plus CytoML and needed dependencies.

It is possible to build on top of these default containers for a
customized Bioconductor container. This is a very good resource for
developers/users who are looking to get an image without having to
worry about system requirements.

We will talk about how to extend these images in the next section.

#### [Bioconda](https://bioconda.github.io/)

Bioconda provides
[**BioContainers**](https://biocontainers.pro/registry/#/).  Bioconda
provides a container for each individual package in Bioconductor under
 the BioContainer umbrella in [Quay.io](https://quay.io).

- They also provide additional "Multi package" container, where you
can combine multiple bioconda packages into one container. You may
choose a Bioconductor package combination of your desire, and build a
container with
them. (https://biocontainers.pro/registry/#/multipackage)

- But please note that they only contain the "release" version of the
Bioconductor packages.

#### [Bioconductor_full](https://github.com/Bioconductor/bioconductor_full)

Bioconductor is now providing an image with a complete set of system
dependencies. The goal of this image is, the user should be able
install every Bioconductor package (1600 +), without having to deal
with system dependency installation.

This complete image can be obtained from [Docker hub](https://cloud.docker.com/u/bioconductor/repository/docker/bioconductor/bioconductor_full).

```
docker pull bioconductor/bioconductor_full:devel

docker pull bioconductor/bioconductor_full:RELEASE_3_9

docker pull bioconductor/bioconductor_full:RELEASE_3_8
```

There are a few exceptions in this list, which are essentially because
of the way these images are built and provisioned.

### Flavors of Bioconductor

The flavors you "need" for your work should be based on the packages
you want for your analysis. There are a list of packages for each
flavor you should evaluate before using the container.

For most beginners a good place to start is the `core2` docker
container.

#### How to extend the image for your needs

There are two ways,

1. Reproducible way:

   Create a new folder `my_image`. Inside that folder, in a new file
   called `Dockerfile`, use the Bioconductor Image most suited for
   your needs as your base using

		## Inherit from the bioconductor/release_base2 image
		FROM bioconductor/release_base2

		## Add packages
		RUN  R -e "BiocManager::install('<package_name>')"

   Then inside the build the new docker image,

		docker build -t my_image:v1 my_image/

2. The interactive way:

	Run the image interactively, with RStudio

		docker run -e PASSWORD=bioc -p 8787:8787 bioconductor/release_base2

		or

		docker run -it bioconductor/release_base2:latest bash

	In localhost:8787

		BiocManager::install('BiocGenerics')

	In another terminal window, note the container ID

		docker ps

	Save the container state,

		docker commit <container ID> my_image:v2

### Mount volumes to your Docker container

It is always a good idea to mount a volume either with data or a list
of installed packages.

You can bind as many mount volumes as needed with the `-v`/`--volume`
command. The format is given as

	-v /host/path:/container/path

If you wanted to share data with your docker container, run the
container with the command,

	docker run \
		-v /data:/home/rstudio/data
		-e PASSWORD=bioc
		-p 8787:8787
		bioconductor/release_base2

To share libraries with your Docker container, bioconductor provides a
way so that the R running within your docker image is able to see the
packages in your container,

	-v /shared-BioC-3.9:/usr/local/lib/R/host-site-library

This location has special meaning, and the configuration within the
bioconductor container allows the user to share built packages. The
path on the docker image that should be mapped to a local R library
directory is /usr/local/lib/R/host-site-library.

1. Create a directory, on your host machine, (as given as whichever
   path suits you the best)

		mkdir /shared-BioC-3.9

2. Run the image by sharing that directory

		docker run \
			-v /shared-BioC-3.9:/usr/local/lib/R/host-site-library \
			-v /data:/home/rstudio/data \
			-it bioconductor/release_base2 R

	Within R,

		BiocManager::install('BiocGenerics')

All the packages in that directory will be directly available to use
instantly. Another big advantage is, it prevents your docker image
from growing in size due to package installation and data. This allows
the users to distribute smaller docker images.


### Conclusion of Beginners section

Re cap of items you have learnt in this section,


## Advanced section - Topics

| Activity                     | Time |
|------------------------------|------|
| Containers on the cloud          | 10m  |
| Mount volumes on the cloud   | 10m  |
| Localize select packages     | 10m  |
| HPC-Singularity containers   | 5m   |
| Launch and run parallel jobs | 10m  |
| Questions                    | 10m+ |
| Future work                  | 5m   |


### Containers on the cloud

#### Requirements

1. Google cloud billing account

	Pro-tip: Create a test google account and you get $300 in billing
    credits for a year. You have to link your credit card to this, so
    make sure you don't leave any google cloud resources running. You
    will go through your $300 USD in credit very quickly.
	
	NOTE: The user is responsible for keeping track of their billing
    account. 

1. You should also have taken the beginners course or at the very
   least have a basic understanding of Docker. If you have missed the
   earlier section please refer back to it for any gaps in the
   information in this section.
   
1. `Google Cloud SDK` needs to be installed, and command line callable
   using `gcloud auth login`.
   
#### Launch a container on the Google cloud

There are a couple of ways this can be done, one is using the a
service on different cloud provides called "Container Engines", the
other by natively using the compute engine service and launching a
container with a specific image.

```
## Launch bioconductor/release_base2:latest image
gcloud compute instances create-with-container bioc-rstudio \
    --container-image bioconductor/release_base2:latest \
    --container-restart-policy never \
##    --container-privileged \
    --container-env PASSWORD=bioc \
    --tags http-server

## Create a firewall
gcloud compute firewall-rules create allow-http \
       --allow tcp:8787 --target-tags http-server

## List running compute instances
gcloud compute instances list

## Stop an instance, NOTE: terminating the instance is your problem!
gcloud compute instances stop rstudio

## Log in to the VM
gcloud compute ssh bioc-rstudio
```

[Google Cloud documentation to configure containers](https://cloud.google.com/compute/docs/containers/configuring-options-to-run-containers)

### Mount volumes on the cloud

You can mount volumes on your VM to your container.

### Localize select packages

Bioconductor provides the 

### HPC-Singularity containers

A few Singularity hub containers you can use on your 

<TODO: HPC singularity brief description>

https://github.com/nturaga/biocparallel_singularity

### Launch and run parallel jobs

Use BiocParallel to launch and run jobs on Singularity containers

### Future work

- Kubernetes

- Helm charts

## References

1. List of protmetcore2 packages

```{r protmetcore2_packages, echo=FALSE, message=FALSE}
library(dplyr)
library(tibble)
url <- "http://www.bioconductor.org/packages/3.10/bioc/VIEWS"
t <- tempfile()
download.file(url, t)
dcf <- as_tibble(read.dcf(t), stringsAsFactors=FALSE)

pkgs <- dcf %>%
    select(biocViews, Package) %>%
    filter(grepl("Metabolomics", biocViews) & grepl("Proteomics", biocViews)) %>%
    pull()

pkgs
```

2. List of metabolomics2 packages

```{r metabolomics2_packages, echo=FALSE, message=FALSE}
pkgs <- dcf %>%
    select(biocViews, Package) %>%
    filter(grepl("Metabolomics", biocViews)) %>%
    pull()

pkgs
```

### sessionInfo

```{r}
sessionInfo()
```

B
